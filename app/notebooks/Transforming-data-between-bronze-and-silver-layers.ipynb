{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68520a9f",
   "metadata": {},
   "source": [
    "# Transforming data between bronze and silver layers - Data Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d85c92",
   "metadata": {},
   "source": [
    "### Configuring access to the Minio/S3 object repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e720514",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b5b0cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Union\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from toml import load\n",
    "from minio import Minio\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "with open(\"credentials.toml\", \"r\") as toml_file:\n",
    "    credentials = load(toml_file)\n",
    "\n",
    "access_key = credentials.get(\"minio_credentials\").get(\"access_key\")\n",
    "secret_key = credentials.get(\"minio_credentials\").get(\"secret_key\")\n",
    "url_minio = credentials.get(\"minio_credentials\").get(\"url_minio\")\n",
    "\n",
    "minio_client = Minio(\n",
    "    url_minio,\n",
    "    access_key=access_key,\n",
    "    secret_key=secret_key,\n",
    "    secure=False,\n",
    "    \n",
    ") \n",
    "\n",
    "\n",
    "def import_objects_bucket(bucket_name: str, path: str, extension:str=\"csv\", sep: str=\";\") -> Union[object, bool]:\n",
    "    \"\"\"\n",
    "    Import all files in the bucket\n",
    "    \"\"\"\n",
    "    try:\n",
    "        objects = minio_client.list_objects(bucket_name, prefix=f\"{path}/\")\n",
    "\n",
    "        list_dataframes = []\n",
    "\n",
    "        for obj in objects:\n",
    "            file_name = obj.object_name\n",
    "\n",
    "            data = minio_client.get_object(bucket_name, file_name)\n",
    "            \n",
    "            if extension == \"parquet\":\n",
    "                tmp_dataframe = pd.read_parquet(BytesIO(data.read()))\n",
    "            else:\n",
    "                tmp_dataframe = pd.read_csv(BytesIO(data.read()), sep=sep)\n",
    "\n",
    "            list_dataframes.append(tmp_dataframe)\n",
    "\n",
    "        return pd.concat(list_dataframes, ignore_index=True)\n",
    "    except Exception as _:\n",
    "        return False\n",
    "\n",
    "def put_dataframe_bucket(dataframe: object, bucket_name: str, path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Writes a dataframe in parquet format to the bucket\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parquet_buffer = BytesIO()\n",
    "        pq.write_table(pa.Table.from_pandas(dataframe), parquet_buffer)\n",
    "        parquet_buffer.seek(0)\n",
    "        \n",
    "        minio_client.put_object(\n",
    "            bucket_name,\n",
    "            f\"{path}/processing_obt_{datetime.now().strftime('%Y%m%d%H%M%S')}.parquet\",\n",
    "            parquet_buffer,\n",
    "            len(parquet_buffer.getvalue())\n",
    "        )\n",
    "        return True\n",
    "    except Exception as _:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec49be4",
   "metadata": {},
   "source": [
    "### Importing bronze layer data for processing - CUSTOMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc9bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_dataframe = import_objects_bucket(\"bronze\", \"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a5cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9740c3d",
   "metadata": {},
   "source": [
    "### Importing bronze layer data for processing - SALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ee8aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_dataframe = import_objects_bucket(\"bronze\", \"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3eaa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d4adf3",
   "metadata": {},
   "source": [
    "### Importing bronze layer data for processing - LOGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fafdfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_dataframe = import_objects_bucket(\"bronze\", \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6274c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd25db1",
   "metadata": {},
   "source": [
    "# Preparation of the data transformation environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2bf8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "connection = duckdb.connect(database=\":memory:\", read_only=False)\n",
    "#connection = duckdb.connect(database=\"data-lake.db\", read_only=False)\n",
    "\n",
    "# Registering dataframes as tables in DuckDB\n",
    "\n",
    "connection.register(\"customers_table\", customers_dataframe)\n",
    "connection.register(\"sales_table\", sales_dataframe)\n",
    "connection.register(\"logs_table\", logs_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8ab575",
   "metadata": {},
   "source": [
    "### Query execution test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca375ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SET memory_limit='10GB';\n",
    "-- SELECT * FROM customers_table;\n",
    "USE memory;\n",
    "SHOW TABLES;\n",
    "\"\"\"\n",
    "result_query = connection.execute(query).df()\n",
    "result_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b1245",
   "metadata": {},
   "source": [
    "### Transformation of the sales base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc10b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "\"\"\"\n",
    "SELECT  customer_id,\n",
    "        count(*) count_sales,\n",
    "        min(sale_datetime) frist_sale_datetime,\n",
    "        max(sale_datetime) last_sale_datetime,\n",
    "        sum(sale_value) amount,\n",
    "        sum(amount_sold) as amount_sold,\n",
    "        sum(amount_pending) as amount_pending,\n",
    "        sum(amount_cancelled) as amount_cancelled,\n",
    "        string_agg(product_and_status, ', ') list_of_products_and_status\n",
    "FROM (\n",
    "    SELECT  customer_id,\n",
    "            cast(concat(sale_date, ' ', lpad(sale_time, 5, '0'), ':00') as timestamp) sale_datetime,\n",
    "            sale_value,\n",
    "            case when sale_status = 'completed' then sale_value else 0.00 end as amount_sold,\n",
    "            case when sale_status = 'pending' then sale_value else 0.00 end as amount_pending,\n",
    "            case when sale_status = 'cancelled' then sale_value else 0.00 end as amount_cancelled,\n",
    "            concat(product_sold, '-', sale_status) product_and_status\n",
    "    FROM sales_table\n",
    "    )\n",
    "GROUP BY customer_id\n",
    "ORDER BY 2 DESC;\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "transformation_sales_result_dataframe = connection.execute(query).df()\n",
    "transformation_sales_result_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a2a20",
   "metadata": {},
   "source": [
    "### Transformation of the logs base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a595a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "\"\"\"\n",
    "-- SELECT * FROM logs_dataframe;\n",
    "\n",
    "SELECT  customer_id,\n",
    "        min(cast(concat(access_date, ' ', lpad(access_time, 5, '0'), ':00') as datetime)) frist_access,\n",
    "        max(cast(concat(access_date, ' ', lpad(access_time, 5, '0'), ':00') as datetime)) last_access,\n",
    "        string_agg(concat(replace(pages_visited, ' ', '_'), '-', device, '-', source_ip), ', ') list_of_access_origin,\n",
    "        round((avg(session_duration) / 60), 0) avg_navigation_in_minutes\n",
    "FROM logs_table\n",
    "GROUP BY customer_id;\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "transformation_logs_result_dataframe = connection.execute(query).df()\n",
    "transformation_logs_result_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb2479",
   "metadata": {},
   "source": [
    "### Consolidation of customer bases, sales and logs into an OBT - One Big Table for silver tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d44c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering dataframes as new tables in DuckDB\n",
    "\n",
    "connection.register(\"transformation_sales_result_table\", transformation_sales_result_dataframe)\n",
    "connection.register(\"transformation_logs_result_table\", transformation_logs_result_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae9ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "\"\"\"\n",
    "SELECT  t1.customer_id,\n",
    "        t1.client_name,\n",
    "        t1.email_address,\n",
    "        t1.phone_number,\n",
    "        t1.registration_date,\n",
    "        t1.date_of_birth,\n",
    "        t1.sex,\n",
    "        t1.address,\n",
    "        t1.city,\n",
    "        coalesce(t1.state, 'Not Found') state,\n",
    "        t1.customer_category,\n",
    "        t2.count_sales,\n",
    "        t2.frist_sale_datetime,\n",
    "        t2.last_sale_datetime,\n",
    "        t2.amount,\n",
    "        t2.amount_sold,\n",
    "        t2.amount_pending,\n",
    "        t2.amount_cancelled,\n",
    "        t2.list_of_products_and_status,\n",
    "        t3.frist_access,\n",
    "        t3.last_access,\n",
    "        t3.list_of_access_origin,\n",
    "        t3.avg_navigation_in_minutes\n",
    "FROM customers_table t1\n",
    "LEFT JOIN transformation_sales_result_table t2\n",
    "ON t1.customer_id = t2.customer_id\n",
    "LEFT JOIN transformation_logs_result_dataframe t3\n",
    "ON t1.customer_id = t3.customer_id\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "result_consolidation_obt_dataframe = connection.execute(query).df()\n",
    "result_consolidation_obt_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1582a78e",
   "metadata": {},
   "source": [
    "# Writing the processing result to the silver layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "put_dataframe_bucket(result_consolidation_obt_dataframe, \"silver\", \"processing_obt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1627396",
   "metadata": {},
   "source": [
    "# Reading existing silver tier data from parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c118f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_obt_dataframe = import_objects_bucket(\"silver\", \"processing_obt\", extension=\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00256480",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_obt_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d703167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering dataframes as new tables in DuckDB\n",
    "\n",
    "connection.register(\"processing_obt_table\", processing_obt_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee8a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mailing list, where I want customers with pending sales who\n",
    "# have already purchased something at some point, and their browsing time \n",
    "# is longer than 5 minutes and the pending amount is greater than 15,000.\n",
    "\n",
    "\n",
    "# Other query examples\n",
    "\n",
    "query_metadata = (\n",
    "\"\"\"\n",
    "-- SELECT  table_name,\n",
    "--         column_name,\n",
    "--         data_type        \n",
    "-- FROM information_schema.columns WHERE table_name = 'processing_obt_table';\n",
    "USE information_schema;\n",
    "SHOW TABLEs;\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "query = (\n",
    "\"\"\"\n",
    "SELECT  customer_id,\n",
    "        client_name,\n",
    "        email_address,\n",
    "        phone_number,\n",
    "        date_diff('year', cast(date_of_birth as date), today()) as idade\n",
    "FROM processing_obt_table\n",
    "WHERE avg_navigation_in_minutes >= 5\n",
    "AND list_of_products_and_status like '%pending%'\n",
    "AND amount_pending > 15000\n",
    "AND amount_sold > 0;\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "result_gold = connection.execute(query).df()\n",
    "result_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33a7720",
   "metadata": {},
   "outputs": [],
   "source": [
    "put_dataframe_bucket(result_gold, \"gold\", \"processing_mailing_list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e4af8",
   "metadata": {},
   "source": [
    "# Viewing the mailing list result on the gold layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3684225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_mailing_list_dataframe = import_objects_bucket(\"gold\", \"processing_mailing_list\", extension=\"parquet\")\n",
    "processing_mailing_list_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce3e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
