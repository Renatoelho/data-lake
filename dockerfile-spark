FROM ubuntu:20.04

SHELL ["/bin/bash", "-c"]

RUN useradd -ms /bin/bash spark -G sudo && \
  passwd -d  spark && \
  mkdir -p /home/spark/app

WORKDIR /home/spark

RUN apt update && \
  apt upgrade -y && \
  apt install \
  python3.8 \
  python3.8-venv \
  systemctl \
  wget \
  nano \
  zip \
  unzip \
  tzdata -y && \
  apt clean

RUN python3 -m venv /home/spark/app/.venv && \
  source /home/spark/app/.venv/bin/activate && \
  pip install -U pip setuptools wheel && \
  pip install pyspark==3.5.0

ENV JAVA_HOME="/home/spark/jdk-11.0.2"
ENV PATH="${JAVA_HOME}/bin/:${PATH}"

ENV SPARK_HOME="/home/spark/spark-3.3.0"
ENV PATH="${SPARK_HOME}/bin/:${PATH}"
ENV PATH="${SPARK_HOME}/sbin/:${PATH}"

ENV SPARK_MASTER_HOST=spark-app
ENV SPARK_MASTER_PORT=7077

ENV PYTHONPATH="${SPARK_HOME}/python/:$PYTHONPATH"
ENV PYTHONPATH="${SPARK_HOME}/python/lib/py4j-0.10.9.5-src.zip:$PYTHONPATH"
ENV PYSPARK_DRIVER_PYTHON="$PYTHONPATH"
ENV PYSPARK_DRIVER_PYTHON_OPTS=notebook
ENV PYSPARK_PYTHON=python3

ENV TZ=America/Sao_Paulo
ENV TERM=xterm-256color

ADD https://download.java.net/java/GA/jdk11/9/GPL/openjdk-11.0.2_linux-x64_bin.tar.gz .
ADD https://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz .

RUN tar xzf openjdk-11.0.2_linux-x64_bin.tar.gz && \
  rm -f openjdk-11.0.2_linux-x64_bin.tar.gz

RUN tar xzf spark-3.3.0-bin-hadoop3.tgz && \
  rm -f spark-3.3.0-bin-hadoop3.tgz && \
  mv spark-3.3.0-bin-hadoop3 /home/spark/spark-3.3.0

#ENTRYPOINT start-master.sh && tail -f /dev/null

ENTRYPOINT tail -f /dev/null